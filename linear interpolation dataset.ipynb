{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a15dc7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 5)\n",
      "DataFrame after linear interpolation:\n",
      "       NOA    NEM     NSR      CP2  Effort (Actual)\n",
      "0    170.0  142.0    97.0   110.55           286.00\n",
      "1    292.0  409.0   295.0   242.54           396.00\n",
      "3    755.0  975.0   723.0   760.96          1016.00\n",
      "5    400.0  225.0   181.0   180.84           261.00\n",
      "6    402.0  589.0   944.0   645.60           993.00\n",
      "7    260.0  262.0   167.0   208.56           552.00\n",
      "8    385.0  697.0   929.0   905.00           998.00\n",
      "11   682.0  789.0   362.0   766.29          1083.00\n",
      "14   770.0  701.0   635.0   743.49           840.00\n",
      "16    65.0   97.0   387.0    74.26           279.00\n",
      "17   293.0  382.0   654.0   481.66           621.00\n",
      "21   637.0  944.0   421.0   627.60           947.00\n",
      "23   520.0  531.0   401.0   590.42           812.00\n",
      "24   812.0  387.0   297.0   428.18           685.00\n",
      "25   788.0  373.0   278.0   280.84           638.00\n",
      "26  1633.0  724.0  1167.0  1719.25          1803.00\n",
      "27   177.0  192.0   126.0   104.50           369.00\n",
      "30   444.0  363.0   398.0   241.40           484.00\n",
      "32   858.0  692.0   653.0   738.70           861.00\n",
      "33   389.0  345.0   245.0   234.08           417.00\n",
      "35   332.0  250.0   512.0   263.07           470.00\n",
      "36   193.0  135.0   121.0   126.38           436.00\n",
      "37   212.0  227.0   147.0   148.35           428.00\n",
      "38   318.0  213.0   183.0   200.10           436.00\n",
      "40    37.0   19.0    30.0    24.02            40.43\n",
      "41    46.0   39.0    15.0    27.93            45.66\n",
      "42    51.0   21.0    15.0    24.29            40.95\n",
      "44    41.0   20.0    13.0    20.66            42.23\n",
      "45    32.0   19.0     8.0    16.48            33.48\n",
      "46    14.0   22.0    15.0    14.24            26.35\n",
      "48    30.0   12.0     8.0    13.96            29.83\n",
      "50    50.0   20.0    14.0    23.46            48.40\n",
      "53    44.0   15.0     8.0    18.71            36.61\n",
      "54    11.0   14.0     8.0     9.22            15.05\n",
      "57    30.0   32.0    17.0    22.06            45.81\n",
      "58    23.0   20.0    11.0    15.08            33.90\n",
      "59    58.0   29.0    24.0    35.12            71.13\n",
      "60    61.0   48.0    31.0    41.34            81.18\n",
      "61    76.0   54.0    29.0    47.52            94.17\n",
      "63    27.0   18.0    14.0    17.31            35.28\n",
      "64    81.0   46.0    32.0    46.48            83.10\n",
      "66    26.0   13.0    16.0    15.36            32.45\n",
      "67    94.0   52.0    28.0    49.86           100.85\n",
      "68    53.0   37.0    19.0    29.26            47.15\n",
      "69    34.0   23.0    17.0    20.68            44.83\n",
      "70   110.0   67.0    36.0    58.47           128.27\n",
      "Performance metrics after linear interpolation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean Absolute Percentage Error</th>\n",
       "      <th>Normalized Mean Squared Error</th>\n",
       "      <th>R^2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>77.181889</td>\n",
       "      <td>7978.330541</td>\n",
       "      <td>0.813411</td>\n",
       "      <td>0.055292</td>\n",
       "      <td>0.944708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>43.989000</td>\n",
       "      <td>6093.538190</td>\n",
       "      <td>0.178196</td>\n",
       "      <td>0.042230</td>\n",
       "      <td>0.957770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP Regressor</td>\n",
       "      <td>48.937193</td>\n",
       "      <td>6646.435149</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.046061</td>\n",
       "      <td>0.953939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>340.166357</td>\n",
       "      <td>138794.938543</td>\n",
       "      <td>4.693324</td>\n",
       "      <td>0.961879</td>\n",
       "      <td>0.038121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMO with Sigmoid Kernel</td>\n",
       "      <td>334.952873</td>\n",
       "      <td>133629.756728</td>\n",
       "      <td>4.658261</td>\n",
       "      <td>0.926083</td>\n",
       "      <td>0.073917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMO with polynomial Kernel</td>\n",
       "      <td>296.430157</td>\n",
       "      <td>113470.898142</td>\n",
       "      <td>3.851487</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.213622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMO with RBF Kernel</td>\n",
       "      <td>340.095823</td>\n",
       "      <td>138811.044965</td>\n",
       "      <td>4.690375</td>\n",
       "      <td>0.961991</td>\n",
       "      <td>0.038009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Absolute Error  Mean Squared Error  \\\n",
       "0           Linear Regression            77.181889         7978.330541   \n",
       "1     Decision Tree Regressor            43.989000         6093.538190   \n",
       "2               MLP Regressor            48.937193         6646.435149   \n",
       "3                         SVR           340.166357       138794.938543   \n",
       "4     SMO with Sigmoid Kernel           334.952873       133629.756728   \n",
       "5  SMO with polynomial Kernel           296.430157       113470.898142   \n",
       "6         SMO with RBF Kernel           340.095823       138811.044965   \n",
       "\n",
       "   Mean Absolute Percentage Error  Normalized Mean Squared Error  R^2 Score  \n",
       "0                        0.813411                       0.055292   0.944708  \n",
       "1                        0.178196                       0.042230   0.957770  \n",
       "2                        0.181819                       0.046061   0.953939  \n",
       "3                        4.693324                       0.961879   0.038121  \n",
       "4                        4.658261                       0.926083   0.073917  \n",
       "5                        3.851487                       0.786378   0.213622  \n",
       "6                        4.690375                       0.961991   0.038009  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#### DATASET WITH DELETED NULL ROWS\n",
    "\n",
    "# Read the dataset and drop the 'Effort (Actual)' column\n",
    "df = pd.read_csv('Effort estimation data set.csv')\n",
    "\n",
    "# Store the 'Effort (Actual)' column separately\n",
    "effort_actual_column = df['Effort (Actual)']\n",
    "\n",
    "# Drop the 'Effort (Actual)' column\n",
    "df.drop(['Effort (Actual)'], axis=1, inplace=True)\n",
    "\n",
    "# Calculate the number of cells to delete (10% of total cells)\n",
    "total_cells = df.size\n",
    "cells_to_delete = int(0.1 * total_cells)\n",
    "\n",
    "# Generate random row and column indices to select cells for deletion\n",
    "indices_to_delete = np.random.choice(df.index, size=cells_to_delete, replace=True)\n",
    "\n",
    "# Set the selected cells as NaN\n",
    "for idx in indices_to_delete:\n",
    "    row_idx, col_idx = np.random.randint(0, df.shape[0]), np.random.randint(0, df.shape[1])\n",
    "    df.iat[row_idx, col_idx] = np.nan\n",
    "\n",
    "# Append the 'Effort (Actual)' column to the modified DataFrame\n",
    "df['Effort (Actual)'] = effort_actual_column\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df\n",
    "\n",
    "#### Dropping rows with NaN values\n",
    "\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Handle missing values with linear interpolation\n",
    "df_interpolated = df.interpolate(method='linear', axis=0)\n",
    "\n",
    "# Display the DataFrame after linear interpolation\n",
    "print(\"DataFrame after linear interpolation:\")\n",
    "print(df_interpolated)\n",
    "\n",
    "#### Splitting the data into training and testing sets\n",
    "\n",
    "X = df_interpolated.drop(columns=['Effort (Actual)'])\n",
    "y = df_interpolated['Effort (Actual)']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#### Linear Regression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "#### Decision Tree Regressor\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "#### MLP Regressor\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "\n",
    "#### SVR\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "svr_pred = svr.predict(X_test)\n",
    "\n",
    "#### SMO with sigmoid kernel (SVR with sigmoid kernel)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svr_sigmoid = SVR(kernel='sigmoid')\n",
    "svr_sigmoid.fit(X_train_scaled, y_train)\n",
    "svr_sigmoid_pred = svr_sigmoid.predict(X_test_scaled)\n",
    "\n",
    "#### SMO with polynomial kernel (SVR with polynomial kernel)\n",
    "\n",
    "svr_poly = SVR(kernel='poly')\n",
    "svr_poly.fit(X_train_scaled, y_train)\n",
    "svr_poly_pred = svr_poly.predict(X_test_scaled)\n",
    "\n",
    "#### SMO with RBF kernel (SVR with RBF kernel)\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "svr_rbf.fit(X_train_scaled, y_train)\n",
    "svr_rbf_pred = svr_rbf.predict(X_test_scaled)\n",
    "\n",
    "#### Evaluate performance metrics for the models\n",
    "\n",
    "# Define a function to calculate normalized mean squared error\n",
    "def normalized_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) / np.var(y_true)\n",
    "\n",
    "# Define a function to calculate performance metrics\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    nmse = normalized_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mse, mape, nmse, r2\n",
    "\n",
    "# Evaluate performance metrics for the models\n",
    "models = [lr, dt, mlp, svr, svr_sigmoid, svr_poly, svr_rbf]\n",
    "predictions = [lr_pred, dt_pred, mlp_pred, svr_pred, svr_sigmoid_pred, svr_poly_pred, svr_rbf_pred]\n",
    "model_names = ['Linear Regression', 'Decision Tree Regressor', 'MLP Regressor', 'SVR', 'SMO with Sigmoid Kernel', 'SMO with polynomial Kernel', 'SMO with RBF Kernel']\n",
    "\n",
    "results = []\n",
    "for model, pred, name in zip(models, predictions, model_names):\n",
    "    mae, mse, mape, nmse, r2 = evaluate_performance(y_test, pred)\n",
    "    results.append([name, mae, mse, mape, nmse, r2])\n",
    "\n",
    "# Create DataFrame from results\n",
    "df_results_interpolated = pd.DataFrame(results, columns=[\"Model\", \"Mean Absolute Error\", \"Mean Squared Error\", \"Mean Absolute Percentage Error\", \"Normalized Mean Squared Error\", \"R^2 Score\"])\n",
    "\n",
    "# Display the results for the models after linear interpolation\n",
    "print(\"Performance metrics after linear interpolation:\")\n",
    "df_results_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019a8c7",
   "metadata": {},
   "source": [
    "Decision Tree Regressor:\n",
    "It has the lowest Mean Absolute Error (MAE) and Mean Squared Error (MSE) among all models, indicating better accuracy in predicting the target variable.\n",
    "It also has the highest R^2 Score, indicating the highest goodness of fit among all models.\n",
    "\n",
    "MLP Regressor:\n",
    "While having slightly higher errors compared to Decision Tree Regressor, MLP Regressor still performs well with relatively low errors and high R^2 Score.\n",
    "\n",
    "Linear Regression:\n",
    "Linear Regression shows good performance with low errors and a high R^2 Score, indicating its effectiveness in predicting the target variable.\n",
    "\n",
    "SMO with Polynomial Kernel:\n",
    "SMO with Polynomial Kernel performs better than the Support Vector Regression (SVR) and SMO with Sigmoid Kernel in terms of errors and R^2 Score, placing it in the fourth position.\n",
    "\n",
    "SMO with RBF Kernel:\n",
    "Despite having similar performance metrics as SVR and SMO with Sigmoid Kernel, SMO with RBF Kernel is placed higher due to the slightly lower Mean Absolute Error (MAE).\n",
    "\n",
    "SMO with Sigmoid Kernel:\n",
    "It performs better than SVR but still exhibits relatively high errors and a low R^2 Score.\n",
    "\n",
    "SVR (Support Vector Regression):\n",
    "SVR shows the poorest performance among all models, with significantly higher errors and a very low R^2 Score.\n",
    "\n",
    "So, the order of models by performance from best to worst is:\n",
    "\n",
    "Decision Tree Regressor\n",
    "\n",
    "MLP Regressor\n",
    "\n",
    "Linear Regression\n",
    "\n",
    "SMO with Polynomial Kernel\n",
    "\n",
    "SMO with RBF Kernel\n",
    "\n",
    "SMO with Sigmoid Kernel\n",
    "\n",
    "SVR (Support Vector Regression)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
