{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LWonm4RKKWV"
   },
   "source": [
    "#### DATASET WITH DELETED NULL ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2gVhUugZpRg2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOA</th>\n",
       "      <th>NEM</th>\n",
       "      <th>NSR</th>\n",
       "      <th>CP2</th>\n",
       "      <th>Effort (Actual)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>110.55</td>\n",
       "      <td>286.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>242.54</td>\n",
       "      <td>396.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>929.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>446.60</td>\n",
       "      <td>471.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>755.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>760.96</td>\n",
       "      <td>1016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>764.0</td>\n",
       "      <td>1242.60</td>\n",
       "      <td>1261.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>94.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>49.86</td>\n",
       "      <td>100.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>53.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.26</td>\n",
       "      <td>47.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.68</td>\n",
       "      <td>44.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>110.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.47</td>\n",
       "      <td>128.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>93.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.12</td>\n",
       "      <td>90.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NOA    NEM    NSR      CP2  Effort (Actual)\n",
       "0   170.0  142.0   97.0   110.55           286.00\n",
       "1   292.0  409.0  295.0   242.54           396.00\n",
       "2   929.0  821.0  567.0   446.60           471.00\n",
       "3   755.0  975.0  723.0   760.96          1016.00\n",
       "4     NaN    NaN  764.0  1242.60          1261.00\n",
       "..    ...    ...    ...      ...              ...\n",
       "67   94.0   52.0   28.0    49.86           100.85\n",
       "68   53.0   37.0    NaN    29.26            47.15\n",
       "69   34.0   23.0   17.0    20.68            44.83\n",
       "70  110.0   67.0   36.0    58.47           128.27\n",
       "71   93.0   76.0    NaN    56.12            90.05\n",
       "\n",
       "[72 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset and drop the 'Effort (Actual)' column\n",
    "df = pd.read_csv('Effort estimation data set.csv')\n",
    "\n",
    "# Store the 'Effort (Actual)' column separately\n",
    "effort_actual_column = df['Effort (Actual)']\n",
    "\n",
    "# Drop the 'Effort (Actual)' column\n",
    "df.drop(['Effort (Actual)'], axis=1, inplace=True)\n",
    "\n",
    "# Calculate the number of cells to delete (10% of total cells)\n",
    "total_cells = df.size\n",
    "cells_to_delete = int(0.1 * total_cells)\n",
    "\n",
    "# Generate random row and column indices to select cells for deletion\n",
    "indices_to_delete = np.random.choice(df.index, size=cells_to_delete, replace=True)\n",
    "\n",
    "# Set the selected cells as NaN\n",
    "for idx in indices_to_delete:\n",
    "    row_idx, col_idx = np.random.randint(0, df.shape[0]), np.random.randint(0, df.shape[1])\n",
    "    df.iat[row_idx, col_idx] = np.nan\n",
    "\n",
    "# Append the 'Effort (Actual)' column to the modified DataFrame\n",
    "df['Effort (Actual)'] = effort_actual_column\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOA</th>\n",
       "      <th>NEM</th>\n",
       "      <th>NSR</th>\n",
       "      <th>CP2</th>\n",
       "      <th>Effort (Actual)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>110.55</td>\n",
       "      <td>286.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>242.54</td>\n",
       "      <td>396.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>929.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>446.60</td>\n",
       "      <td>471.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>755.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>760.96</td>\n",
       "      <td>1016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>208.56</td>\n",
       "      <td>552.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>385.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>905.00</td>\n",
       "      <td>998.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>95.06</td>\n",
       "      <td>180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>559.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>251.55</td>\n",
       "      <td>482.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>98.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>64.61</td>\n",
       "      <td>205.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1087.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1345.40</td>\n",
       "      <td>1414.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>304.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>438.90</td>\n",
       "      <td>680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>299.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>262.74</td>\n",
       "      <td>366.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>637.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>627.60</td>\n",
       "      <td>947.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>451.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>358.60</td>\n",
       "      <td>485.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>520.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>590.42</td>\n",
       "      <td>812.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>812.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>428.18</td>\n",
       "      <td>685.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>788.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>280.84</td>\n",
       "      <td>638.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1633.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>1719.25</td>\n",
       "      <td>1803.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>177.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>104.50</td>\n",
       "      <td>369.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>181.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>156.64</td>\n",
       "      <td>439.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>285.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>246.96</td>\n",
       "      <td>491.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>444.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>241.40</td>\n",
       "      <td>484.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>389.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>413.10</td>\n",
       "      <td>481.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>858.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>653.0</td>\n",
       "      <td>738.70</td>\n",
       "      <td>861.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>332.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>263.07</td>\n",
       "      <td>470.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>193.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>126.38</td>\n",
       "      <td>436.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>212.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>148.35</td>\n",
       "      <td>428.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>318.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>200.10</td>\n",
       "      <td>436.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>46.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.93</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.29</td>\n",
       "      <td>40.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.72</td>\n",
       "      <td>51.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.66</td>\n",
       "      <td>42.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.48</td>\n",
       "      <td>33.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.36</td>\n",
       "      <td>32.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.26</td>\n",
       "      <td>9.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.46</td>\n",
       "      <td>48.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.68</td>\n",
       "      <td>29.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.68</td>\n",
       "      <td>23.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.71</td>\n",
       "      <td>36.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>15.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>34.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.28</td>\n",
       "      <td>51.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.23</td>\n",
       "      <td>71.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.08</td>\n",
       "      <td>33.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41.34</td>\n",
       "      <td>81.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>76.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>47.52</td>\n",
       "      <td>94.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>81.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46.48</td>\n",
       "      <td>83.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.13</td>\n",
       "      <td>40.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.36</td>\n",
       "      <td>32.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>94.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>49.86</td>\n",
       "      <td>100.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.68</td>\n",
       "      <td>44.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>110.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.47</td>\n",
       "      <td>128.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NOA    NEM     NSR      CP2  Effort (Actual)\n",
       "0    170.0  142.0    97.0   110.55           286.00\n",
       "1    292.0  409.0   295.0   242.54           396.00\n",
       "2    929.0  821.0   567.0   446.60           471.00\n",
       "3    755.0  975.0   723.0   760.96          1016.00\n",
       "7    260.0  262.0   167.0   208.56           552.00\n",
       "8    385.0  697.0   929.0   905.00           998.00\n",
       "9     77.0   71.0   218.0    95.06           180.00\n",
       "10   559.0  368.0   504.0   251.55           482.00\n",
       "12    98.0   79.0    41.0    64.61           205.00\n",
       "15  1087.0  885.0   701.0  1345.40          1414.00\n",
       "19   304.0  347.0   870.0   438.90           680.00\n",
       "20   299.0  343.0   264.0   262.74           366.00\n",
       "21   637.0  944.0   421.0   627.60           947.00\n",
       "22   451.0  409.0   269.0   358.60           485.00\n",
       "23   520.0  531.0   401.0   590.42           812.00\n",
       "24   812.0  387.0   297.0   428.18           685.00\n",
       "25   788.0  373.0   278.0   280.84           638.00\n",
       "26  1633.0  724.0  1167.0  1719.25          1803.00\n",
       "27   177.0  192.0   126.0   104.50           369.00\n",
       "28   181.0  169.0   128.0   156.64           439.00\n",
       "29   285.0  323.0   195.0   246.96           491.00\n",
       "30   444.0  363.0   398.0   241.40           484.00\n",
       "31   389.0  431.0   362.0   413.10           481.00\n",
       "32   858.0  692.0   653.0   738.70           861.00\n",
       "35   332.0  250.0   512.0   263.07           470.00\n",
       "36   193.0  135.0   121.0   126.38           436.00\n",
       "37   212.0  227.0   147.0   148.35           428.00\n",
       "38   318.0  213.0   183.0   200.10           436.00\n",
       "41    46.0   39.0    15.0    27.93            45.66\n",
       "42    51.0   21.0    15.0    24.29            40.95\n",
       "43    55.0   44.0    11.0    30.72            51.83\n",
       "44    41.0   20.0    13.0    20.66            42.23\n",
       "45    32.0   19.0     8.0    16.48            33.48\n",
       "47    26.0   13.0    16.0    15.36            32.41\n",
       "49    11.0    7.0     8.0     7.26             9.43\n",
       "50    50.0   20.0    14.0    23.46            48.40\n",
       "51    18.0   19.0    12.0    13.68            29.31\n",
       "52    22.0   19.0     8.0    13.68            23.31\n",
       "53    44.0   15.0     8.0    18.71            36.61\n",
       "54    11.0   14.0     8.0     9.22            15.05\n",
       "55    34.0   55.0    23.0    31.28            51.86\n",
       "56    40.0   48.0    31.0    33.23            71.48\n",
       "58    23.0   20.0    11.0    15.08            33.90\n",
       "60    61.0   48.0    31.0    41.34            81.18\n",
       "61    76.0   54.0    29.0    47.52            94.17\n",
       "64    81.0   46.0    32.0    46.48            83.10\n",
       "65    24.0   31.0    19.0    20.13            40.92\n",
       "66    26.0   13.0    16.0    15.36            32.45\n",
       "67    94.0   52.0    28.0    49.86           100.85\n",
       "69    34.0   23.0    17.0    20.68            44.83\n",
       "70   110.0   67.0    36.0    58.47           128.27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Effort (Actual)'])\n",
    "y = df['Effort (Actual)']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor()\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "svr_pred = svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMO with sigmoid kernel (SVR with sigmoid kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svr_sigmoid = SVR(kernel='sigmoid')\n",
    "svr_sigmoid.fit(X_train_scaled, y_train)\n",
    "svr_sigmoid_pred = svr_sigmoid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMO with polynomial kernel (SVR with polynomial kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_poly = SVR(kernel='poly')\n",
    "svr_poly.fit(X_train_scaled, y_train)\n",
    "svr_poly_pred = svr_poly.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMO with RBF kernel (SVR with RBF kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf')\n",
    "svr_rbf.fit(X_train_scaled, y_train)\n",
    "svr_rbf_pred = svr_rbf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean Absolute Percentage Error</th>\n",
       "      <th>Normalized Mean Squared Error</th>\n",
       "      <th>R^2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>82.146751</td>\n",
       "      <td>10800.944436</td>\n",
       "      <td>0.783733</td>\n",
       "      <td>0.035367</td>\n",
       "      <td>0.964633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>89.136364</td>\n",
       "      <td>20052.338418</td>\n",
       "      <td>0.256539</td>\n",
       "      <td>0.065661</td>\n",
       "      <td>0.934339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP Regressor</td>\n",
       "      <td>37.568921</td>\n",
       "      <td>3513.196454</td>\n",
       "      <td>0.108709</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.988496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>422.507656</td>\n",
       "      <td>316807.494118</td>\n",
       "      <td>3.388000</td>\n",
       "      <td>1.037379</td>\n",
       "      <td>-0.037379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMO with Sigmoid Kernel</td>\n",
       "      <td>412.233828</td>\n",
       "      <td>302228.032986</td>\n",
       "      <td>3.327428</td>\n",
       "      <td>0.989639</td>\n",
       "      <td>0.010361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMO with polynomial Kernel</td>\n",
       "      <td>344.776806</td>\n",
       "      <td>243544.399836</td>\n",
       "      <td>2.535595</td>\n",
       "      <td>0.797480</td>\n",
       "      <td>0.202520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMO with RBF Kernel</td>\n",
       "      <td>422.467637</td>\n",
       "      <td>316876.726099</td>\n",
       "      <td>3.385063</td>\n",
       "      <td>1.037605</td>\n",
       "      <td>-0.037605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Absolute Error  Mean Squared Error  \\\n",
       "0           Linear Regression            82.146751        10800.944436   \n",
       "1     Decision Tree Regressor            89.136364        20052.338418   \n",
       "2               MLP Regressor            37.568921         3513.196454   \n",
       "3                         SVR           422.507656       316807.494118   \n",
       "4     SMO with Sigmoid Kernel           412.233828       302228.032986   \n",
       "5  SMO with polynomial Kernel           344.776806       243544.399836   \n",
       "6         SMO with RBF Kernel           422.467637       316876.726099   \n",
       "\n",
       "   Mean Absolute Percentage Error  Normalized Mean Squared Error  R^2 Score  \n",
       "0                        0.783733                       0.035367   0.964633  \n",
       "1                        0.256539                       0.065661   0.934339  \n",
       "2                        0.108709                       0.011504   0.988496  \n",
       "3                        3.388000                       1.037379  -0.037379  \n",
       "4                        3.327428                       0.989639   0.010361  \n",
       "5                        2.535595                       0.797480   0.202520  \n",
       "6                        3.385063                       1.037605  -0.037605  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to calculate normalized mean squared error\n",
    "def normalized_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) / np.var(y_true)\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    nmse = normalized_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, mse, mape, nmse, r2\n",
    "\n",
    "# Evaluate performance metrics for the models\n",
    "models = [lr, dt, mlp, svr, svr_sigmoid, svr_poly, svr_rbf]\n",
    "predictions = [lr_pred, dt_pred, mlp_pred, svr_pred, svr_sigmoid_pred, svr_poly_pred, svr_rbf_pred]\n",
    "model_names = ['Linear Regression', 'Decision Tree Regressor', 'MLP Regressor', 'SVR', 'SMO with Sigmoid Kernel', 'SMO with polynomial Kernel', 'SMO with RBF Kernel']\n",
    "\n",
    "results = []\n",
    "for model, pred, name in zip(models, predictions, model_names):\n",
    "    mae, mse, mape, nmse, r2 = evaluate_performance(y_test, pred)\n",
    "    results.append([name, mae, mse, mape, nmse, r2])\n",
    "\n",
    "# Create DataFrame from results\n",
    "df_results = pd.DataFrame(results, columns=[\"Model\", \"Mean Absolute Error\", \"Mean Squared Error\", \"Mean Absolute Percentage Error\", \"Normalized Mean Squared Error\", \"R^2 Score\"])\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
